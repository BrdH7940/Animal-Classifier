{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "# This cell installs all the required libraries with their specific versions.\n",
        "%pip install tensorflow==2.16.1\n",
        "%pip install numpy==1.26.4\n",
        "%pip install pandas==2.2.2\n",
        "%pip install scikit-learn==1.5.0\n",
        "%pip install tensorflow-datasets==4.9.4\n",
        "%pip install mlflow==2.14.1\n",
        "%pip install matplotlib==3.9.0\n",
        "%pip install seaborn==0.13.2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Main Experiment Script\n",
        "import mlflow\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# --- Keras Callback for MLflow Logging ---\n",
        "class MLflowLogger(tf.keras.callbacks.Callback):\n",
        "    \"\"\"Keras callback to log metrics for each epoch.\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        mlflow.log_metric('epoch_loss', logs.get('loss'), step=epoch)\n",
        "        mlflow.log_metric('epoch_accuracy', logs.get('accuracy'), step=epoch)\n",
        "        mlflow.log_metric('epoch_val_loss', logs.get('val_loss'), step=epoch)\n",
        "        mlflow.log_metric('epoch_val_accuracy', logs.get('val_accuracy'), step=epoch)\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    \"\"\"Generates and saves a confusion matrix plot.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    \n",
        "    # In Kaggle, files are often saved in /kaggle/working/\n",
        "    if not os.path.exists(\"artifacts\"):\n",
        "        os.makedirs(\"artifacts\")\n",
        "        \n",
        "    path = os.path.join(\"artifacts\", \"confusion_matrix.png\")\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def run_experiment():\n",
        "    # --- 1. Load and Preprocess Data ---\n",
        "    print(\"Fetching and preparing MNIST dataset...\")\n",
        "    mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
        "    X, y = mnist[\"data\"], mnist[\"target\"].astype(np.uint8)\n",
        "\n",
        "    # Normalize pixel values to be between 0 and 1\n",
        "    X = X / 255.0\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    # Reshape data for the neural network\n",
        "    X_train = X_train.reshape(-1, 28, 28)\n",
        "    X_test = X_test.reshape(-1, 28, 28)\n",
        "    \n",
        "    class_names = np.unique(y).astype(str)\n",
        "    print(\"Dataset ready.\")\n",
        "\n",
        "    # --- 2. Define Hyperparameters and Model ---\n",
        "    params = {\n",
        "        'epochs': 10,\n",
        "        'batch_size': 64,\n",
        "        'learning_rate': 0.001\n",
        "    }\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # --- 3. MLflow Experiment Tracking ---\n",
        "    mlflow.set_experiment(\"Advanced MNIST Classification (Neural Network)\")\n",
        "\n",
        "    with mlflow.start_run() as run:\n",
        "        print(f\"Starting MLflow Run: {run.info.run_name}\")\n",
        "        mlflow.log_params(params)\n",
        "\n",
        "        print(\"Training model...\")\n",
        "        model.fit(X_train, y_train, \n",
        "                  validation_split=0.2,\n",
        "                  epochs=params['epochs'], \n",
        "                  batch_size=params['batch_size'],\n",
        "                  callbacks=[MLflowLogger()],\n",
        "                  verbose=2)\n",
        "        print(\"Model training completed.\")\n",
        "        \n",
        "        # --- 4. Log Artifacts ---\n",
        "        # Log the final model\n",
        "        mlflow.keras.log_model(model, artifact_path=\"model\")\n",
        "\n",
        "        # Generate predictions for evaluation\n",
        "        y_pred_probs = model.predict(X_test)\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "        # Generate and log the confusion matrix\n",
        "        print(\"Generating and logging confusion matrix...\")\n",
        "        cm_path = plot_confusion_matrix(y_test, y_pred, class_names)\n",
        "        mlflow.log_artifact(cm_path, \"plots\")\n",
        "        \n",
        "    print(\"\\n--- MLflow Run Completed ---\")\n",
        "    print(\"You can now view the results in the MLflow UI.\")\n",
        "\n",
        "# Run the main function\n",
        "run_experiment()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3: Viewing the Results\n",
        "\n",
        "### How to View the MLflow UI\n",
        "\n",
        "After running the experiment in the cell above, a new directory named `mlruns` will be created in your notebook's environment. This directory contains all the tracking data.\n",
        "\n",
        "To view the interactive MLflow dashboard, you would typically run the command `mlflow ui` from a terminal in the same directory. However, in environments like Kaggle or Colab, you can't directly access the local server.\n",
        "\n",
        "**Option 1: Download the `mlruns` directory**\n",
        "\n",
        "You can download the entire `mlruns` folder, run `mlflow ui` on your local machine from the directory where you downloaded it, and explore the results there.\n",
        "\n",
        "**Option 2: Using `ngrok` (Advanced)**\n",
        "\n",
        "For a live view, you can use a tool like `ngrok` to create a public URL for the MLflow UI server. This involves running the UI in the background and then exposing its port (usually 5000) through ngrok.\n",
        "\n",
        "Example commands:\n",
        "```bash\n",
        "# Install ngrok\n",
        "!pip install pyngrok\n",
        "\n",
        "# Run mlflow ui in the background\n",
        "!mlflow ui --host 0.0.0.0 &\n",
        "\n",
        "# Expose the port using ngrok\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Click this link to view the MLflow UI: {public_url}\")\n",
        "```\n",
        "You would run these in a new code cell after the experiment is complete.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Package and Download Results\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# The MLflow data is stored in the 'mlruns' directory.\n",
        "# We will compress this directory into a zip file for easy download.\n",
        "if os.path.exists('mlruns'):\n",
        "    shutil.make_archive('mlruns_results', 'zip', 'mlruns')\n",
        "    print(\"Successfully created 'mlruns_results.zip'.\")\n",
        "    print(\"\\n--> You can now find 'mlruns_results.zip' in the file viewer on the right-hand side of your Kaggle notebook.\")\n",
        "    print(\"--> Click on it and then select 'Download' to save it to your local machine.\")\n",
        "else:\n",
        "    print(\"The 'mlruns' directory was not found. Please run the experiment cell (Cell 2) first.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
